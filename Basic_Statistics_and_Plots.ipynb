{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random data generation\n",
    "- Summary and descriptive statistics\n",
    "- Sample covariance and correlation\n",
    "- Cross tabulation\n",
    "- Frequent items\n",
    "- Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql.functions import rand, randn\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql.functions import mean, min, max\n",
    "from pyspark.sql.functions import struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Data Generation\n",
    "We start with some simple methods for generating columns that contains independently and identically distributed values drawn from a distribution, e.g., uniform (rand), and standard normal (randn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with one int column and 10 rows.\n",
    "df = sqlContext.range(0, 10)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate two other columns using uniform distribution and normal distribution.\n",
    "df.select(\"id\", rand(seed=10).alias(\"uniform\"), randn(seed=27).alias(\"normal\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot bar graph of data; id column on x-axis and uniform column on y-axis\n",
    "plt.clf()\n",
    "pdDF = df.toPandas()\n",
    "pdDF.plot(x='id', y='uniform', kind='bar', rot=45)\n",
    "display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What went wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the table we tried to plot\n",
    "pdDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that the original dataframe just consists of one column; id. \n",
    "\n",
    "But what we are interested in is the columns generated from a uniform distribution and a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change the dataframe so that it includes these two columns (before we generated them but didn't add them to the dataframe)\n",
    "df = df.select(\"id\", rand(seed=10).alias(\"uniform\"), randn(seed=27).alias(\"normal\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# A slightly different way to generate two random columns\n",
    "df = sqlContext.range(0, 10).withColumn('uniform', rand(seed=10)).withColumn('normal', randn(seed=27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change spark dataframe to pandas dataframe\n",
    "pdDF = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot bar graph of data; id column on x-axis and uniform column on y-axis\n",
    "plt.clf()\n",
    "pdDF.plot(x='id', y='uniform', kind='bar', rot=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot histogram of data; frequency of the unifrom distribution\n",
    "plt.clf()\n",
    "pdDF.plot(x='id', y='uniform', kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram shows the frequency of data items in successive numerical intervals of equal size. \n",
    "The independent variable (the y-values in the bar graph above) is plotted along the horizontal axis and the dependent variable (the frequency of the occurences) is plotted along the vertical axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Understanding the Data: Descriptive Statistics\n",
    "The first operation to perform after importing data is to get some sense of what the data looks like. The function <b>describe</b> returns information such as number of non-null entries (count), mean, standard deviation, and minimum and maximum value for each numerical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show column names and types\n",
    "df.describe()\n",
    "\n",
    "# show specific column names and types\n",
    "# display(df.describe('uniform', 'normal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the count, mean, standard deviation, min and max values from a DataFrame: use the describe() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# overview of data frame\n",
    "df.describe().show()\n",
    "\n",
    "# overview of specific columns\n",
    "# df.describe('uniform', 'normal').show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Find mean, min, max of the column uniform\n",
    "sel_col = 'uniform'\n",
    "df.select([F.mean(sel_col), F.min(sel_col), F.max(sel_col)]).show()\n",
    "\n",
    "# show data type of the column uniform\n",
    "display(df.select([F.mean(sel_col), F.min(sel_col), F.max(sel_col)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Quantile\n",
    "we will find the minimum, median and maximum from the uniform column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pandas = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pandas.uniform.mean()   # Same as df['uniform'].mean()\n",
    "\n",
    "df_pandas.uniform.median() \n",
    "\n",
    "# You can call `quantile(i)` to get the i'th quantile,\n",
    "# where `i` should be a fractional number.\n",
    "\n",
    "df_pandas.uniform.quantile(0.1) # 10th percentile\n",
    "\n",
    "df_pandas.uniform.quantile(0.5) # same as median\n",
    "\n",
    "df_pandas.uniform.quantile(0.9) # 90th percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sample covariance and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'covariance = ' + str(df.stat.cov('uniform', 'normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'covariance = ' + str(df.stat.cov('id', 'id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation is a normalized measure of covariance that is easier to understand, as it provides quantitative measurements of the statistical dependence between two random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'correlation = ' + str(df.stat.corr('uniform', 'normal'))\n",
    "\n",
    "print 'correlation = ' + str(df.stat.corr('id', 'id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cross Tabulation (Contingency Table)\n",
    "Cross Tabulation provides a table of the frequency distribution for a set of variables. It is used to observe the statistical significance (or independence) of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with two columns (name, item)\n",
    "names = [\"Alice\", \"Bob\", \"Mike\"]\n",
    "items = [\"milk\", \"bread\", \"butter\", \"apples\", \"oranges\"]\n",
    "df = sqlContext.createDataFrame([(names[i % 3], items[i % 5]) for i in range(100)], [\"name\", \"item\"])\n",
    "\n",
    "# Take a look at the first 10 rows.\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.stat.crosstab(\"name\", \"item\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Frequent Items\n",
    "Figuring out which items are frequent in each column can be very useful to understand a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's find the items that show up 40% of the time for each column:\n",
    "df.stat.freqItems([\"item\"], 0.4).show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot graphs with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# linear graph\n",
    "plt.clf\n",
    "plt.plot([1,2,3,4])\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot([1, 2, 3, 4], [1, 4, 9, 16])\n",
    "plt.plot([1,2,3,4], [1,4,9,16], 'ro')\n",
    "plt.axis([0, 6, 0, 20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with multiple figures and axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = np.linspace(0.0, 5.0)\n",
    "x2 = np.linspace(0.0, 2.0)\n",
    "\n",
    "y1 = np.cos(2 * np.pi * x1) * np.exp(-x1)\n",
    "y2 = np.cos(2 * np.pi * x2)\n",
    "\n",
    "plt.subplot(2, 1, 1) # the first subplot\n",
    "plt.plot(x1, y1, 'o-')\n",
    "plt.title('A tale of 2 subplots')\n",
    "plt.ylabel('Damped oscillation')\n",
    "\n",
    "plt.subplot(2, 1, 2) # the second subplot\n",
    "plt.plot(x2, y2, '.-')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('Undamped')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data for plotting\n",
    "t = np.arange(0.0, 2.0, 0.01)\n",
    "s = 1 + np.sin(2 * np.pi * t)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, s)\n",
    "\n",
    "ax.set(xlabel='time (s)', ylabel='voltage (mV)',\n",
    "       title='About as simple as it gets, folks')\n",
    "ax.grid()\n",
    "\n",
    "plt.annotate('local max', xy=(1.25, 2), xytext=(3, 1.5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "            )\n",
    "\n",
    "fig.savefig(\"test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's create pre-defined labels and a modified legend\n",
    "a = b = np.arange(0, 3, .02)\n",
    "c = np.exp(a)\n",
    "d = c[::-1]\n",
    "\n",
    "# Create plots with pre-defined labels.\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(a, c, 'k--', label='Model length')\n",
    "ax.plot(a, d, 'k:', label='Data length')\n",
    "ax.plot(a, c + d, 'k', label='Total message length')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='x-large')\n",
    "\n",
    "# Put a nicer background color on the legend.\n",
    "legend.get_frame().set_facecolor('C0')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bar plot with multiple data sets\n",
    "plt.clf\n",
    "df2 = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])\n",
    "df2.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Demo of the histogram (hist) function with a few features such as setting the number of data bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.normal(size = 1000)\n",
    "plt.hist(x, normed=True, bins=30)\n",
    "plt.ylabel('Probability');\n",
    "plt.xlabel('Numbers from a normal distribution');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n",
    "sizes = [15, 30, 45, 10]\n",
    "explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some fun Jupyter commands to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%magic\n",
    "%lsmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out the magic cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%latex\n",
    "\\begin{equation}\n",
    "   E = mc^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<HTML>\n",
    "    <HEAD>\n",
    "        <TITLE>Your Title Here</TITLE>\n",
    "    </HEAD>\n",
    "<BODY BGCOLOR=\"FFFFFF\">\n",
    "    <HR>\n",
    "        <a href=\"http://somegreatsite.com\">Link Name</a> is a link to another nifty site\n",
    "        <H1>This is a Header</H1>\n",
    "        <H2>This is a Medium Header</H2>\n",
    "        Send me a mail at <a href=\"mailto:anna.baecklund@swedbank.se\">\n",
    "        anna.baecklund@swedbank.se</a>.\n",
    "        <P> This is a new paragraph!\n",
    "        <P> <B>This is a new paragraph!</B>\n",
    "        <BR> <B><I>This is a new sentence without a paragraph break, in bold italics.</I></B>\n",
    "    <HR>\n",
    "</BODY>\n",
    "</HTML>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "min = 1\n",
    "max = 6\n",
    "\n",
    "roll_again = \"yes\"\n",
    "\n",
    "while roll_again == \"yes\" or roll_again == \"y\":\n",
    "    print \"Rolling the dices...\"\n",
    "    print \"The values are....\"\n",
    "    print random.randint(min, max)\n",
    "    print random.randint(min, max)\n",
    "\n",
    "    roll_again = raw_input(\"Roll the dices again? \")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Use This DL pySpark (Spark 2.2)",
   "language": "python",
   "name": "usethis_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
